{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Assignment 3\n\n Welcome to Assignment 3. This will be even more fun. Now we will calculate statistical measures.\n\n## You only have to pass 4 out of 7 functions\n\nJust make sure you hit the play button on each cell from top to down. There are seven functions you have to implement. Please also make sure than on each change on a function you hit the play button again on the corresponding cell to make it available to the rest of this notebook.\n\nThis notebook is designed to run in a IBM Watson Studio default runtime (NOT the Watson Studio Apache Spark Runtime as the default runtime with 1 vCPU is free of charge). Therefore, we install Apache Spark in local mode for test purposes only. Please don't use it in production.\n\nIn case you are facing issues, please read the following two documents first:\n\n https://github.com/IBM/skillsnetwork/wiki/Environment-Setup\n \n https://github.com/IBM/skillsnetwork/wiki/FAQ\n\nThen, please feel free to ask:\n\n https://coursera.org/learn/machine-learning-big-data-apache-spark/discussions/all\n\nPlease make sure to follow the guidelines before asking a question:\n\nhttps://github.com/IBM/skillsnetwork/wiki/FAQ#im-feeling-lost-and-confused-please-help-me\n\n\nIf running outside Watson Studio, this should work as well. In case you are running in an Apache Spark context outside Watson Studio, please remove the Apache Spark setup in the first notebook cells."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Markdown, display\n\ndef printmd(string):\n    display(Markdown('## <span style=\"color:green\">'+string+'</span>'))",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "if ('sc' in locals() or 'sc' in globals()):\n    print(\"Please do not use Apache Watson Studio.\")\nelse:\n    print(\"All is good. Let's go.\")",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "All is good. Let's go.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install pyspark==2.4.5",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: pyspark==2.4.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (2.4.5)\r\nRequirement already satisfied: py4j==0.10.7 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyspark==2.4.5) (0.10.7)\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "All functions can be implemented using DataFrames, ApacheSparkSQL or RDDs. We are only interested in the result. You are given the reference to the data frame in the \\\"df\\\" parameter and in case you want to use SQL just use the \\\"spark\\\" parameter which is a reference to the global SparkSession object. Finally if you want to use RDDs just use \\\"df.rdd\\\" for obtaining a reference to the underlying RDD object. But we discurage using RDD at this point in time.\n\nLet's start with the first function. Please calculate the minimal temperature for the test data set you have created. We've provided a little skeleton for you in case you want to use SQL. Everything can be implemented using SQL only if you like."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def minTemperature():\n    return spark.sql('SELECT min(temperature) AS mintemp FROM washing').first().mintemp",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def meanTemperature():\n    return spark.sql('SELECT mean(temperature) AS meantemp FROM washing').first().meantemp",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def maxTemperature():\n    return spark.sql('SELECT max(temperature) AS maxtemp FROM washing').first().maxtemp",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def sdTemperature():\n    return spark.sql('SELECT stddev(temperature) AS sdtemp FROM washing').first().sdtemp",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def skewTemperature():\n    return spark.sql('SELECT skewness(temperature) AS skewness FROM washing').first().skewness\n            ",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def kurtosisTemperature():\n    return spark.sql('SELECT kurtosis(temperature) AS kurtosis FROM washing').first().kurtosis",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def correlationTemperatureHardness():\n    return spark.sql('SELECT corr(temperature,hardness) AS corrl FROM washing').first().corrl",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget https://github.com/IBM/coursera/blob/master/coursera_ds/washing.parquet?raw=true\n!mv washing.parquet?raw=true washing.parquet",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2020-12-19 23:23:30--  https://github.com/IBM/coursera/blob/master/coursera_ds/washing.parquet?raw=true\nResolving github.com (github.com)... 140.82.113.3\nConnecting to github.com (github.com)|140.82.113.3|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://github.com/IBM/skillsnetwork/blob/master/coursera_ds/washing.parquet?raw=true [following]\n--2020-12-19 23:23:31--  https://github.com/IBM/skillsnetwork/blob/master/coursera_ds/washing.parquet?raw=true\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github.com/IBM/skillsnetwork/raw/master/coursera_ds/washing.parquet [following]\n--2020-12-19 23:23:31--  https://github.com/IBM/skillsnetwork/raw/master/coursera_ds/washing.parquet\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/IBM/skillsnetwork/master/coursera_ds/washing.parquet [following]\n--2020-12-19 23:23:31--  https://raw.githubusercontent.com/IBM/skillsnetwork/master/coursera_ds/washing.parquet\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 112048 (109K) [application/octet-stream]\nSaving to: \u2018washing.parquet?raw=true\u2019\n\n100%[======================================>] 112,048     --.-K/s   in 0.002s  \n\n2020-12-19 23:23:31 (60.8 MB/s) - \u2018washing.parquet?raw=true\u2019 saved [112048/112048]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df = spark.read.parquet('washing.parquet')\ndf.createOrReplaceTempView('washing')\ndf.show()",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n|                 _id|                _rev|count|flowrate|fluidlevel|frequency|hardness|speed|temperature|           ts|voltage|\n+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n|0d86485d0f88d1f9d...|1-57940679fb8a713...|    4|      11|acceptable|     null|      77| null|        100|1547808723923|   null|\n|0d86485d0f88d1f9d...|1-15ff3a0b304d789...|    2|    null|      null|     null|    null| 1046|       null|1547808729917|   null|\n|0d86485d0f88d1f9d...|1-97c2742b68c7b07...|    4|    null|      null|       71|    null| null|       null|1547808731918|    236|\n|0d86485d0f88d1f9d...|1-eefb903dbe45746...|   19|      11|acceptable|     null|      75| null|         86|1547808738999|   null|\n|0d86485d0f88d1f9d...|1-5f68b4c72813c25...|    7|    null|      null|       75|    null| null|       null|1547808740927|    235|\n|0d86485d0f88d1f9d...|1-cd4b6c57ddbe77e...|    5|    null|      null|     null|    null| 1014|       null|1547808744923|   null|\n|0d86485d0f88d1f9d...|1-a35b25b5bf43aaf...|   32|      11|acceptable|     null|      73| null|         84|1547808752028|   null|\n|0d86485d0f88d1f9d...|1-b717f7289a8476d...|   48|      11|acceptable|     null|      79| null|         84|1547808768065|   null|\n|0d86485d0f88d1f9d...|1-c2f1f8fcf178b2f...|   18|    null|      null|       73|    null| null|       null|1547808773944|    228|\n|0d86485d0f88d1f9d...|1-15033dd9eebb4a8...|   59|      11|acceptable|     null|      72| null|         96|1547808779093|   null|\n|0d86485d0f88d1f9d...|1-753dae825f9a6c2...|   62|      11|acceptable|     null|      73| null|         88|1547808782113|   null|\n|0d86485d0f88d1f9d...|1-b168089f44f03f0...|   13|    null|      null|     null|    null| 1097|       null|1547808784940|   null|\n|0d86485d0f88d1f9d...|1-403b687c6be0dea...|   23|    null|      null|       80|    null| null|       null|1547808788955|    236|\n|0d86485d0f88d1f9d...|1-195551e0455a24b...|   72|      11|acceptable|     null|      77| null|         87|1547808792134|   null|\n|0d86485d0f88d1f9d...|1-060a39fc6c2ddee...|   26|    null|      null|       62|    null| null|       null|1547808797959|    233|\n|0d86485d0f88d1f9d...|1-2234514bffee465...|   27|    null|      null|       61|    null| null|       null|1547808800960|    226|\n|0d86485d0f88d1f9d...|1-4265898bb401db0...|   82|      11|acceptable|     null|      79| null|         96|1547808802154|   null|\n|0d86485d0f88d1f9d...|1-2fbf7ca9a0425a0...|   94|      11|acceptable|     null|      73| null|         90|1547808814186|   null|\n|0d86485d0f88d1f9d...|1-203c0ee6d7fbd21...|   97|      11|acceptable|     null|      77| null|         88|1547808817190|   null|\n|0d86485d0f88d1f9d...|1-47e1965db94fcab...|  104|      11|acceptable|     null|      75| null|         80|1547808824198|   null|\n+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "min_temperature = 0\nmean_temperature = 0\nmax_temperature = 0\nsd_temperature = 0\nskew_temperature = 0\nkurtosis_temperature = 0,\ncorrelation_temperature = 0",
            "execution_count": 15,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "min_temperature = minTemperature()\nprint(min_temperature)",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "80\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mean_temperature = meanTemperature()\nprint(mean_temperature)",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "90.03800298062593\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "max_temperature = maxTemperature()\nprint(max_temperature)",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "100\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "sd_temperature = sdTemperature()\nprint(sd_temperature)",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "6.1007610586219725\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "skew_temperature = skewTemperature()\nprint(skew_temperature)",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "0.010410008042945581\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "kurtosis_temperature = kurtosisTemperature()\nprint(kurtosis_temperature)",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "-1.2239269305786886\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "correlation_temperature = correlationTemperatureHardness()\nprint(correlation_temperature)",
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "0.017754069047296324\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!rm -f rklib.py\\n\",\n!wget https://raw.githubusercontent.com/IBM/coursera/master/rklib.py",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/usr/bin/sh: -c: line 0: unexpected EOF while looking for matching `\"'\n/usr/bin/sh: -c: line 1: syntax error: unexpected end of file\n--2020-12-19 23:23:49--  https://raw.githubusercontent.com/IBM/coursera/master/rklib.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2540 (2.5K) [text/plain]\nSaving to: \u2018rklib.py.1\u2019\n\n100%[======================================>] 2,540       --.-K/s   in 0s      \n\n2020-12-19 23:23:49 (13.9 MB/s) - \u2018rklib.py.1\u2019 saved [2540/2540]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from rklib import submitAll\nimport json\n\nkey = \"Suy4biHNEeimFQ479R3GjA\"\nemail = \"jonah.winninghoff@gmail.com\", jonah.winninghoff@gmail.\ntoken = \"de9tKRdZQdI0OUKP\"",
            "execution_count": 25,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "parts_data = {}\nparts_data[\"FWMEL\"] = json.dumps(min_temperature)\nparts_data[\"3n3TK\"] = json.dumps(mean_temperature)\nparts_data[\"KD3By\"] = json.dumps(max_temperature)\nparts_data[\"06Zie\"] = json.dumps(sd_temperature)\nparts_data[\"Qc8bI\"] = json.dumps(skew_temperature)\nparts_data[\"LoqQi\"] = json.dumps(kurtosis_temperature)\nparts_data[\"ehNGV\"] = json.dumps(correlation_temperature)\n\n\n\nsubmitAll(email, token, key, parts_data)",
            "execution_count": 45,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Something went wrong, please have a look at the reponse of the grader\n-------------------------\n{\"errorCode\":null,\"message\":\"JSON didn't validate\",\"details\":{\"/submitterEmail\":[{\"message\":\"error.expected.jsstring\",\"args\":[]}]}}\n-------------------------\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
